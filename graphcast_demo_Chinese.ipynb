{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jAYlxeKxvAJ"
      },
      "source": [
        "# 从零开始运行 GraphCast （AutoDL 或者其他新的环境）\n",
        "-------------------------------------------------------------------\n",
        "**这是从 https://google-deepmind/graphcast 复现的项目。由 https://github.com/sfsun67 改写和调试。**\n",
        "\n",
        "**AutoDL 是国内的一家云计算平台，网址是https://www.autodl.com**\n",
        "\n",
        "你应该有类似的文件结构，这里的数据由 Google Cloud Bucket (https://console.cloud.google.com/storage/browser/dm_graphcast 提供：\n",
        "```\n",
        ".\n",
        "├── code\n",
        "│   ├── graphcast-main\n",
        "│       ├──graphcast\n",
        "│       ├──tree\n",
        "│       ├──wrapt\n",
        "│       ├──graphcast_demo.ipynb\n",
        "│       ├──README.md\n",
        "│       ├──setup.py\n",
        "│       ├──...\n",
        "├── data\n",
        "│   ├── dataset\n",
        "│       ├──dataset-source-era5_date-2022-01-01_res-1.0_levels-13_steps-01.nc\n",
        "│       ├──dataset-source-era5_date-2022-01-01_res-1.0_levels-13_steps-04.nc\n",
        "│       ├──dataset-source-era5_date-2022-01-01_res-1.0_levels-13_steps-12.nc\n",
        "│       ├──...\n",
        "│   ├── params\n",
        "│       ├──params-GraphCast - ERA5 1979-2017 - resolution 0.25 - pressure levels 37 - mesh 2to6 - precipitation input and output.npz\n",
        "│       ├──params-GraphCast_small - ERA5 1979-2015 - resolution 1.0 - pressure levels 13 - mesh 2to5 - precipitation input and output.npz\n",
        "│       ├──...\n",
        "│   ├── stats\n",
        "│       ├──stats-mean_by_level.nc\n",
        "│       ├──...\n",
        "└────── \n",
        "```\n",
        "\n",
        "PS: \n",
        "1. Python 要使用3.10版本。老版本会出现函数调用失效的问题。\n",
        "2. 你需要仔细核对包的版本，防止出现意外的错误。例如， xarray 只能使用 2023.7.0 版本，其他版本会出现错误。\n",
        "3. 你需要仔细核对所有包是否安装正确。未安装的包会导致意外错误。例如，tree 和 wrapt 是两个 GraphCast 所必需的包，但是并不在源文件中。例如，tree 和 wrapt 中的 .os 文件未导入，会引发循环调用。他们的原始文件可以在 Colaboratory(https://colab.research.google.com/github/deepmind/graphcast/blob/master/graphcast_demo.ipynb) 的环境中找到。\n",
        "\n",
        "\n",
        "\n",
        "*代码在如下机器上测试*\n",
        "1. GPU: TITAN Xp 12GB; CPU: Xeon(R) E5-2680 v4;  JAX / 0.3.10 / 3.8(ubuntu18.04) / 11.1\n",
        "2. GPU: V100-SXM2-32GB 32GB; CPU: Xeon(R) Platinum 8255C; JAX / 0.3.10 / 3.8(ubuntu18.04) / 11.1\n",
        "-------------------------------------------------------------------\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<p><small><small>版权所有 2023 年 DeepMind Technologies Limited。</small></small></p>\n",
        "<p><small><small>根据 Apache 许可证第 2.0 版（\"许可证\"）获得许可；除非符合许可证的规定，否则您不得使用此文件。您可以在 <a href=\"http://www.apache.org/licenses/LICENSE-2.0\">http://www.apache.org/licenses/LICENSE-2.0</a> 获取许可证的副本。</small></small></p>\n",
        "<p><small><small>除非适用法律要求或书面同意，根据许可证分发的软件是基于 \"按原样\" 分发的，没有任何明示或暗示的担保或条件。有关许可证下的具体语言，请参见许可证中的权限和限制。</small></small></p>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 将 Python 版本更新到 3.10.\n",
        "\n",
        "GraphCast 需要 Python >= 3.10 。推荐 Python 3.10。\n",
        "\n",
        "在终端中，新建一个名为 GraphCast 的环境。\n",
        "\n",
        "参考代码如下：\n",
        "```\n",
        "\n",
        "# 更新 conda （可选）\n",
        "conda update -n base -c defaults conda\n",
        "\n",
        "# 在新环境 GraphCast 中安装 python=3.10  \n",
        "conda create -n GraphCast python=3.10    \n",
        "\n",
        "# 更新bashrc中的环境变量\n",
        "conda init bash && source /root/.bashrc\n",
        "\n",
        "# 激活新的环境\n",
        "conda activate GraphCast\n",
        "\n",
        "# 验证版本\n",
        "python\n",
        "```\n",
        "\n",
        "\n",
        "注意：验证版本之后，重启jupyter，使用新的内核。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yMbbXFl4msJw"
      },
      "source": [
        "# 安装和初始化\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 学术资源加速 https://www.autodl.com/docs/network_turbo/  .\n",
        "\n",
        "import subprocess\n",
        "import os\n",
        "\n",
        "result = subprocess.run('bash -c \"source /etc/network_turbo && env | grep proxy\"', shell=True, capture_output=True, text=True)\n",
        "output = result.stdout\n",
        "for line in output.splitlines():\n",
        "    if '=' in line:\n",
        "        var, value = line.split('=', 1)\n",
        "        os.environ[var] = value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 这一步将使用 shapely 安装环境。为了避免出现ERROR： 无法为 shapely 构建轮子，而安装基于 pyproject.toml 的项目需要轮子。\n",
        "\n",
        "!pip uninstall -y shapely\n",
        "!conda install -y shapely\n",
        "!pip uninstall -y shapely"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-W4K9skv9vh-"
      },
      "outputs": [],
      "source": [
        "# @title Pip 安装 graphcast 和其他依赖项\n",
        "\n",
        "\n",
        "%pip install --upgrade https://github.com/deepmind/graphcast/archive/master.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "MA5087Vb29z2"
      },
      "outputs": [],
      "source": [
        "# @title cartopy 崩溃的解决方法\n",
        "\n",
        "!pip uninstall -y shapely\n",
        "!pip install shapely --no-binary shapely"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 安装其他依赖项，并解决 xarray 的版本问题。\n",
        "\n",
        "# 这里需要将xarray的版本从2023.12.0(2023年12月30日安装)降低到2023.7.0，否则会报错。\n",
        "\n",
        "!conda install -y -c conda-forge ipywidgets\n",
        "!pip uninstall -y xarray\n",
        "!pip install xarray==2023.7.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Z_j8ej4Pyg1L"
      },
      "outputs": [],
      "source": [
        "# @title 导入库\n",
        "\n",
        "\n",
        "import dataclasses\n",
        "import datetime\n",
        "import functools\n",
        "import math\n",
        "import re\n",
        "from typing import Optional\n",
        "\n",
        "import cartopy.crs as ccrs\n",
        "#from google.cloud import storage\n",
        "from graphcast import autoregressive\n",
        "from graphcast import casting\n",
        "from graphcast import checkpoint\n",
        "from graphcast import data_utils\n",
        "from graphcast import graphcast\n",
        "from graphcast import normalization\n",
        "from graphcast import rollout\n",
        "from graphcast import xarray_jax\n",
        "from graphcast import xarray_tree\n",
        "from IPython.display import HTML\n",
        "import ipywidgets as widgets\n",
        "import haiku as hk\n",
        "import jax\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation\n",
        "import numpy as np\n",
        "import xarray\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def parse_file_parts(file_name):\n",
        "  return dict(part.split(\"-\", 1) for part in file_name.split(\"_\"))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "5JUymx84dI2m"
      },
      "outputs": [],
      "source": [
        "# @title 载入绘图函数\n",
        "\n",
        "\n",
        "def select(\n",
        "    data: xarray.Dataset,\n",
        "    variable: str,\n",
        "    level: Optional[int] = None,\n",
        "    max_steps: Optional[int] = None\n",
        "    ) -> xarray.Dataset:\n",
        "  data = data[variable]\n",
        "  if \"batch\" in data.dims:\n",
        "    data = data.isel(batch=0)\n",
        "  if max_steps is not None and \"time\" in data.sizes and max_steps < data.sizes[\"time\"]:\n",
        "    data = data.isel(time=range(0, max_steps))\n",
        "  if level is not None and \"level\" in data.coords:\n",
        "    data = data.sel(level=level)\n",
        "  return data\n",
        "\n",
        "def scale(\n",
        "    data: xarray.Dataset,\n",
        "    center: Optional[float] = None,\n",
        "    robust: bool = False,\n",
        "    ) -> tuple[xarray.Dataset, matplotlib.colors.Normalize, str]:\n",
        "  vmin = np.nanpercentile(data, (2 if robust else 0))\n",
        "  vmax = np.nanpercentile(data, (98 if robust else 100))\n",
        "  if center is not None:\n",
        "    diff = max(vmax - center, center - vmin)\n",
        "    vmin = center - diff\n",
        "    vmax = center + diff\n",
        "  return (data, matplotlib.colors.Normalize(vmin, vmax),\n",
        "          (\"RdBu_r\" if center is not None else \"viridis\"))\n",
        "\n",
        "def plot_data(\n",
        "    data: dict[str, xarray.Dataset],\n",
        "    fig_title: str,\n",
        "    plot_size: float = 5,\n",
        "    robust: bool = False,\n",
        "    cols: int = 4\n",
        "    ) -> tuple[xarray.Dataset, matplotlib.colors.Normalize, str]:\n",
        "\n",
        "  first_data = next(iter(data.values()))[0]\n",
        "  max_steps = first_data.sizes.get(\"time\", 1)\n",
        "  assert all(max_steps == d.sizes.get(\"time\", 1) for d, _, _ in data.values())\n",
        "\n",
        "  cols = min(cols, len(data))\n",
        "  rows = math.ceil(len(data) / cols)\n",
        "  figure = plt.figure(figsize=(plot_size * 2 * cols,\n",
        "                               plot_size * rows))\n",
        "  figure.suptitle(fig_title, fontsize=16)\n",
        "  figure.subplots_adjust(wspace=0, hspace=0)\n",
        "  figure.tight_layout()\n",
        "\n",
        "  images = []\n",
        "  for i, (title, (plot_data, norm, cmap)) in enumerate(data.items()):\n",
        "    ax = figure.add_subplot(rows, cols, i+1)\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "    ax.set_title(title)\n",
        "    im = ax.imshow(\n",
        "        plot_data.isel(time=0, missing_dims=\"ignore\"), norm=norm,\n",
        "        origin=\"lower\", cmap=cmap)\n",
        "    plt.colorbar(\n",
        "        mappable=im,\n",
        "        ax=ax,\n",
        "        orientation=\"vertical\",\n",
        "        pad=0.02,\n",
        "        aspect=16,\n",
        "        shrink=0.75,\n",
        "        cmap=cmap,\n",
        "        extend=(\"both\" if robust else \"neither\"))\n",
        "    images.append(im)\n",
        "\n",
        "  def update(frame):\n",
        "    if \"time\" in first_data.dims:\n",
        "      td = datetime.timedelta(microseconds=first_data[\"time\"][frame].item() / 1000)\n",
        "      figure.suptitle(f\"{fig_title}, {td}\", fontsize=16)\n",
        "    else:\n",
        "      figure.suptitle(fig_title, fontsize=16)\n",
        "    for im, (plot_data, norm, cmap) in zip(images, data.values()):\n",
        "      im.set_data(plot_data.isel(time=frame, missing_dims=\"ignore\"))\n",
        "\n",
        "  ani = animation.FuncAnimation(\n",
        "      fig=figure, func=update, frames=max_steps, interval=250)\n",
        "  plt.close(figure.number)\n",
        "  return HTML(ani.to_jshtml())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEtSV8HEkHtf"
      },
      "source": [
        "# 加载数据并初始化模型"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 载入模型参数\n",
        "\n",
        "选择两种获取模型参数的方式之一：\n",
        "- **random**：您将获得随机预测，但您可以更改模型架构，这可能会使其运行更快或适应您的设备。\n",
        "- **checkpoint**：您将获得明智的预测，但受限于模型训练时使用的架构，这可能不适合您的设备。特别是生成梯度会使用大量内存，因此您至少需要25GB的内存（TPUv4或A100）。\n",
        "\n",
        "检查点在一些方面有所不同：\n",
        "- 网格大小指定了地球的内部图形表示。较小的网格将运行更快，但输出将更差。网格大小不影响模型的参数数量。\n",
        "- 分辨率和压力级别的数量必须匹配数据。较低的分辨率和较少的级别会运行得更快。数据分辨率仅影响编码器/解码器。\n",
        "- 我们的所有模型都预测降水。然而，ERA5包含降水，而HRES不包含。我们标记为 \"ERA5\" 的模型将降水作为输入，并期望以ERA5数据作为输入，而标记为 \"ERA5-HRES\" 的模型不以降水作为输入，并专门训练以HRES-fc0作为输入（请参阅下面的数据部分）。\n",
        "\n",
        "我们提供三个预训练模型：\n",
        "1. `GraphCast`，用于GraphCast论文的高分辨率模型（0.25度分辨率，37个压力级别），在1979年至2017年间使用ERA5数据进行训练，\n",
        "\n",
        "2. `GraphCast_small`，GraphCast的较小低分辨率版本（1度分辨率，13个压力级别和较小的网格），在1979年至2015年间使用ERA5数据进行训练，适用于具有较低内存和计算约束的模型运行，\n",
        "\n",
        "3. `GraphCast_operational`，一个高分辨率模型（0.25度分辨率，13个压力级别），在1979年至2017年使用ERA5数据进行预训练，并在2016年至2021年间使用HRES数据进行微调。此模型可以从HRES数据初始化（不需要降水输入）。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title 选择模型\n",
        "# Rewrite by S.F. Sune, https://github.com/sfsun67.\n",
        "'''\n",
        "    我们有三种训练好的模型可供选择, 需要从https://console.cloud.google.com/storage/browser/dm_graphcast准备：\n",
        "    GraphCast - ERA5 1979-2017 - resolution 0.25 - pressure levels 37 - mesh 2to6 - precipitation input and output.npz\n",
        "    GraphCast_operational - ERA5-HRES 1979-2021 - resolution 0.25 - pressure levels 13 - mesh 2to6 - precipitation output only.npz\n",
        "    GraphCast_small - ERA5 1979-2015 - resolution 1.0 - pressure levels 13 - mesh 2to5 - precipitation input and output.npz\n",
        "'''\n",
        "# 在此路径 /root/autodl-fs/data/params 中查找结果，并列出 \"params/\"中所有文件的名称，去掉名称中的 \"params/\"perfix。\n",
        "\n",
        "import os\n",
        "import glob\n",
        "\n",
        "# 定义数据目录，请替换成你自己的目录。\n",
        "dir_path_params = \"/root/autodl-fs/data/params\"\n",
        "\n",
        "# Use glob to get all file paths in the directory\n",
        "file_paths_params = glob.glob(os.path.join(dir_path_params, \"*\"))\n",
        "\n",
        "# Remove the directory path and the \".../params/\" prefix from each file name\n",
        "params_file_options = [os.path.basename(path) for path in file_paths_params]\n",
        "\n",
        "\n",
        "random_mesh_size = widgets.IntSlider(\n",
        "    value=4, min=4, max=6, description=\"Mesh size:\")\n",
        "random_gnn_msg_steps = widgets.IntSlider(\n",
        "    value=4, min=1, max=32, description=\"GNN message steps:\")\n",
        "random_latent_size = widgets.Dropdown(\n",
        "    options=[int(2**i) for i in range(4, 10)], value=32,description=\"Latent size:\")\n",
        "random_levels = widgets.Dropdown(\n",
        "    options=[13, 37], value=13, description=\"Pressure levels:\")\n",
        "\n",
        "\n",
        "params_file = widgets.Dropdown(\n",
        "    options=params_file_options,\n",
        "    description=\"Params file:\",\n",
        "    layout={\"width\": \"max-content\"})\n",
        "\n",
        "source_tab = widgets.Tab([\n",
        "    widgets.VBox([\n",
        "        random_mesh_size,\n",
        "        random_gnn_msg_steps,\n",
        "        random_latent_size,\n",
        "        random_levels,\n",
        "    ]),\n",
        "    params_file,\n",
        "])\n",
        "source_tab.set_title(0, \"随机参数权重（Random）\")\n",
        "source_tab.set_title(1, \"预训练权重（Checkpoint）\")\n",
        "widgets.VBox([\n",
        "    source_tab,\n",
        "    widgets.Label(value=\"运行下一个单元格以加载模型。重新运行该单元格将清除您的选择。\")\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lYQgrPgPdI2n"
      },
      "outputs": [],
      "source": [
        "# @title 加载模型\n",
        "\n",
        "source = source_tab.get_title(source_tab.selected_index)\n",
        "\n",
        "if source == \"随机参数权重（Random）\":\n",
        "  params = None  # Filled in below\n",
        "  state = {}\n",
        "  model_config = graphcast.ModelConfig(\n",
        "      resolution=0,\n",
        "      mesh_size=random_mesh_size.value,\n",
        "      latent_size=random_latent_size.value,\n",
        "      gnn_msg_steps=random_gnn_msg_steps.value,\n",
        "      hidden_layers=1,\n",
        "      radius_query_fraction_edge_length=0.6)\n",
        "  task_config = graphcast.TaskConfig(\n",
        "      input_variables=graphcast.TASK.input_variables,\n",
        "      target_variables=graphcast.TASK.target_variables,\n",
        "      forcing_variables=graphcast.TASK.forcing_variables,\n",
        "      pressure_levels=graphcast.PRESSURE_LEVELS[random_levels.value],\n",
        "      input_duration=graphcast.TASK.input_duration,\n",
        "  )\n",
        "else:\n",
        "  assert source == \"预训练权重（Checkpoint）\"\n",
        "  '''with gcs_bucket.blob(f\"params/{params_file.value}\").open(\"rb\") as f:\n",
        "    ckpt = checkpoint.load(f, graphcast.CheckPoint)'''\n",
        "  \n",
        "  with open(f\"{dir_path_params}/{params_file.value}\", \"rb\") as f:\n",
        "    ckpt = checkpoint.load(f, graphcast.CheckPoint)\n",
        "  \n",
        "  params = ckpt.params\n",
        "  state = {}\n",
        "\n",
        "  model_config = ckpt.model_config\n",
        "  task_config = ckpt.task_config\n",
        "  print(\"模型描述:\\n\", ckpt.description, \"\\n\")\n",
        "  print(\"模型许可信息:\\n\", ckpt.license, \"\\n\")\n",
        "\n",
        "model_config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQWk0RRuCjDN"
      },
      "source": [
        "## 载入示例数据\n",
        "\n",
        "有几个示例数据集可用，在几个坐标轴上各不相同：\n",
        "- **来源**：fake、era5、hres\n",
        "- **分辨率**：0.25度、1度、6度\n",
        "- **级别**：13, 37\n",
        "- **步数**：包含多少个时间步\n",
        "\n",
        "并非所有组合都可用。\n",
        "- 由于加载内存的要求，较高分辨率只适用于较少的步数。\n",
        "- HRES 只有 0.25 度，13 个压力等级。\n",
        "\n",
        "数据分辨率必须与加载的模型相匹配。\n",
        "\n",
        "对基础数据集进行了一些转换：\n",
        "- 我们累积了 6 个小时的降水量，而不是默认的 1 个小时。\n",
        "- 对于 HRES 数据，每个时间步对应 HRES 在前导时间 0 的预报，实际上提供了 HRES 的 \"初始化\"。有关详细描述，请参见 GraphCast 论文中的 HRES-fc0。请注意，HRES 无法提供 6 小时的累积降水量，因此我们的模型以 HRES 输入不依赖于降水。但由于我们的模型可以预测降水，因此在示例数据中包含了 ERA5 降水量，以作为地面真实情况的示例。\n",
        "- 我们在数据中加入了 ERA5 的 \"toa_incident_solar_radiation\"。我们的模型使用 -6h、0h 和 +6h 辐射作为每 1 步预测的强迫项。在运行中，如果没有现成的 +6h 辐射，可以使用诸如 `pysolar` 等软件包计算辐射。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "-DJzie5me2-H"
      },
      "outputs": [],
      "source": [
        "# @title 获取和筛选可用示例数据的列表\n",
        "\n",
        "# Rewrite by S.F. Sune, https://github.com/sfsun67.\n",
        "# 在“/root/autodl-fs/data/dataset”路径下查找结果，并列出“dataset/”中所有文件的名称列表，去掉“dataset/”前缀。\n",
        "\n",
        "# 定义数据目录，请替换成你自己的目录。\n",
        "dir_path_dataset = \"/root/autodl-fs/data/dataset\"\n",
        "\n",
        "# Use glob to get all file paths in the directory\n",
        "file_paths_dataset = glob.glob(os.path.join(dir_path_dataset, \"*\"))\n",
        "\n",
        "# Remove the directory path and the \".../params/\" prefix from each file name\n",
        "dataset_file_options = [os.path.basename(path) for path in file_paths_dataset]\n",
        "#print(\"dataset_file_options: \", dataset_file_options)\n",
        "\n",
        "# Remove \"dataset-\" prefix from each file name\n",
        "dataset_file_options = [name.removeprefix(\"dataset-\") for name in dataset_file_options]\n",
        "\n",
        "\n",
        "def data_valid_for_model(\n",
        "    file_name: str, model_config: graphcast.ModelConfig, task_config: graphcast.TaskConfig):\n",
        "  file_parts = parse_file_parts(file_name.removesuffix(\".nc\"))\n",
        "  #print(\"file_parts: \", file_parts)\n",
        "  return (\n",
        "      model_config.resolution in (0, float(file_parts[\"res\"])) and\n",
        "      len(task_config.pressure_levels) == int(file_parts[\"levels\"]) and\n",
        "      (\n",
        "          (\"total_precipitation_6hr\" in task_config.input_variables and\n",
        "           file_parts[\"source\"] in (\"era5\", \"fake\")) or\n",
        "          (\"total_precipitation_6hr\" not in task_config.input_variables and\n",
        "           file_parts[\"source\"] in (\"hres\", \"fake\"))\n",
        "      )\n",
        "  )\n",
        "\n",
        "\n",
        "dataset_file = widgets.Dropdown(\n",
        "    options=[\n",
        "        (\", \".join([f\"{k}: {v}\" for k, v in parse_file_parts(option.removesuffix(\".nc\")).items()]), option)\n",
        "        for option in dataset_file_options\n",
        "        if data_valid_for_model(option, model_config, task_config)\n",
        "    ],\n",
        "    description=\"数据文件:\",\n",
        "    layout={\"width\": \"max-content\"})\n",
        "widgets.VBox([\n",
        "    dataset_file,\n",
        "    widgets.Label(value=\"运行下一个单元格以加载数据集。重新运行此单元格将清除您的选择，并重新筛选与您的模型匹配的数据集。\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Yz-ekISoJxeZ"
      },
      "outputs": [],
      "source": [
        "# @title 加载气象数据\n",
        "\n",
        "\n",
        "if not data_valid_for_model(dataset_file.value, model_config, task_config):\n",
        "  raise ValueError(\n",
        "      \"Invalid dataset file, rerun the cell above and choose a valid dataset file.\")\n",
        "\n",
        "'''with gcs_bucket.blob(f\"dataset/{dataset_file.value}\").open(\"rb\") as f:\n",
        "  example_batch = xarray.load_dataset(f).compute()'''\n",
        "\n",
        "with open(f\"{dir_path_dataset}/dataset-{dataset_file.value}\", \"rb\") as f:\n",
        "  example_batch = xarray.load_dataset(f).compute()\n",
        "\n",
        "assert example_batch.dims[\"time\"] >= 3  # 2 for input, >=1 for targets\n",
        "\n",
        "print(\", \".join([f\"{k}: {v}\" for k, v in parse_file_parts(dataset_file.value.removesuffix(\".nc\")).items()]))\n",
        "\n",
        "example_batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "lXjFvdE6qStr"
      },
      "outputs": [],
      "source": [
        "# @title 选择绘图数据\n",
        "\n",
        "plot_example_variable = widgets.Dropdown(\n",
        "    options=example_batch.data_vars.keys(),\n",
        "    value=\"2m_temperature\",\n",
        "    description=\"变量\")\n",
        "plot_example_level = widgets.Dropdown(\n",
        "    options=example_batch.coords[\"level\"].values,\n",
        "    value=500,\n",
        "    description=\"级别\")\n",
        "plot_example_robust = widgets.Checkbox(value=True, description=\"鲁棒性\")\n",
        "plot_example_max_steps = widgets.IntSlider(\n",
        "    min=1, max=example_batch.dims[\"time\"], value=example_batch.dims[\"time\"],\n",
        "    description=\"最大步\")\n",
        "\n",
        "widgets.VBox([\n",
        "    plot_example_variable,\n",
        "    plot_example_level,\n",
        "    plot_example_robust,\n",
        "    plot_example_max_steps,\n",
        "    widgets.Label(value=\"运行下一个单元格以绘制数据。重新运行此单元格将清除您的选择。\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "kIK-EgMdkHtk"
      },
      "outputs": [],
      "source": [
        "# @title 绘制示例数据\n",
        "\n",
        "\n",
        "plot_size = 7\n",
        "\n",
        "data = {\n",
        "    \" \": scale(select(example_batch, plot_example_variable.value, plot_example_level.value, plot_example_max_steps.value),\n",
        "              robust=plot_example_robust.value),\n",
        "}\n",
        "fig_title = plot_example_variable.value\n",
        "if \"等级\" in example_batch[plot_example_variable.value].coords:\n",
        "  fig_title += f\" at {plot_example_level.value} hPa\"\n",
        "\n",
        "plot_data(data, fig_title, plot_size, plot_example_robust.value)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tPVy1GHokHtk"
      },
      "outputs": [],
      "source": [
        "# @title 选择要提取的训练和评估数据\n",
        "\n",
        "train_steps = widgets.IntSlider(\n",
        "    value=1, min=1, max=example_batch.sizes[\"time\"]-2, description=\"训练步数\")\n",
        "eval_steps = widgets.IntSlider(\n",
        "    value=example_batch.sizes[\"time\"]-2, min=1, max=example_batch.sizes[\"time\"]-2, description=\"评估步数\")\n",
        "\n",
        "widgets.VBox([\n",
        "    train_steps,\n",
        "    eval_steps,\n",
        "    widgets.Label(value=\"运行下一个单元格以提取数据。重新运行此单元格将清除您的选择。\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Ogp4vTBvsgSt"
      },
      "outputs": [],
      "source": [
        "# @title 提取训练和评估数据\n",
        "\n",
        "train_inputs, train_targets, train_forcings = data_utils.extract_inputs_targets_forcings(\n",
        "    example_batch, target_lead_times=slice(\"6h\", f\"{train_steps.value*6}h\"),\n",
        "    **dataclasses.asdict(task_config))\n",
        "\n",
        "eval_inputs, eval_targets, eval_forcings = data_utils.extract_inputs_targets_forcings(\n",
        "    example_batch, target_lead_times=slice(\"6h\", f\"{eval_steps.value*6}h\"),\n",
        "    **dataclasses.asdict(task_config))\n",
        "\n",
        "print(\"所有示例：  \", example_batch.dims.mapping)\n",
        "print(\"训练输入：  \", train_inputs.dims.mapping)\n",
        "print(\"训练目标： \", train_targets.dims.mapping)\n",
        "print(\"训练强迫：\", train_forcings.dims.mapping)\n",
        "print(\"评估输入：   \", eval_inputs.dims.mapping)\n",
        "print(\"评估目标：  \", eval_targets.dims.mapping)\n",
        "print(\"评估强迫项: \", eval_forcings.dims.mapping)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Q--ZRhpTdI2o"
      },
      "outputs": [],
      "source": [
        "# @title 加载规范化数据\n",
        "# Rewrite by S.F. Sune, https://github.com/sfsun67.\n",
        "dir_path_stats = \"/root/autodl-fs/data/stats\"\n",
        "\n",
        "with open(f\"{dir_path_stats}/stats-diffs_stddev_by_level.nc\", \"rb\") as f:\n",
        "  diffs_stddev_by_level = xarray.load_dataset(f).compute()\n",
        "with open(f\"{dir_path_stats}/stats-mean_by_level.nc\", \"rb\") as f:\n",
        "  mean_by_level = xarray.load_dataset(f).compute()\n",
        "with open(f\"{dir_path_stats}/stats-stddev_by_level.nc\", \"rb\") as f:\n",
        "  stddev_by_level = xarray.load_dataset(f).compute()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ke2zQyuT_sMA"
      },
      "outputs": [],
      "source": [
        "# @title 构建 jitted 函数，并可能初始化随机权重\n",
        "# 构建模型并初始化权重\n",
        "\n",
        "# 模型组网\n",
        "def construct_wrapped_graphcast(\n",
        "    model_config: graphcast.ModelConfig,\n",
        "    task_config: graphcast.TaskConfig):\n",
        "  \"\"\"Constructs and wraps the GraphCast Predictor.\"\"\"\n",
        "  # Deeper one-step predictor.\n",
        "  predictor = graphcast.GraphCast(model_config, task_config)\n",
        "\n",
        "  # Modify inputs/outputs to `graphcast.GraphCast` to handle conversion to\n",
        "  # from/to float32 to/from BFloat16.\n",
        "  predictor = casting.Bfloat16Cast(predictor)\n",
        "\n",
        "  # Modify inputs/outputs to `casting.Bfloat16Cast` so the casting to/from\n",
        "  # BFloat16 happens after applying normalization to the inputs/targets.\n",
        "  predictor = normalization.InputsAndResiduals(\n",
        "      predictor,\n",
        "      diffs_stddev_by_level=diffs_stddev_by_level,\n",
        "      mean_by_level=mean_by_level,\n",
        "      stddev_by_level=stddev_by_level)\n",
        "\n",
        "  # Wraps everything so the one-step model can produce trajectories.\n",
        "  predictor = autoregressive.Predictor(predictor, gradient_checkpointing=True)\n",
        "  return predictor\n",
        "\n",
        "# 前向运算\n",
        "@hk.transform_with_state\n",
        "def run_forward(model_config, task_config, inputs, targets_template, forcings):\n",
        "  predictor = construct_wrapped_graphcast(model_config, task_config)\n",
        "  return predictor(inputs, targets_template=targets_template, forcings=forcings)\n",
        "\n",
        "# 计算损失函数\n",
        "@hk.transform_with_state    # used to convert a pure function into a stateful function\n",
        "def loss_fn(model_config, task_config, inputs, targets, forcings):\n",
        "  predictor = construct_wrapped_graphcast(model_config, task_config)    # constructs and wraps a GraphCast Predictor, which is a model used for making predictions in a graph-based machine learning task.\n",
        "  loss, diagnostics = predictor.loss(inputs, targets, forcings)\n",
        "  return xarray_tree.map_structure(\n",
        "      lambda x: xarray_jax.unwrap_data(x.mean(), require_jax=True),\n",
        "      (loss, diagnostics))\n",
        "\n",
        "# 计算梯度\n",
        "def grads_fn(params, state, model_config, task_config, inputs, targets, forcings):\n",
        "  def _aux(params, state, i, t, f):\n",
        "    (loss, diagnostics), next_state = loss_fn.apply(\n",
        "        params, state, jax.random.PRNGKey(0), model_config, task_config,\n",
        "        i, t, f)\n",
        "    return loss, (diagnostics, next_state)\n",
        "  (loss, (diagnostics, next_state)), grads = jax.value_and_grad(\n",
        "      _aux, has_aux=True)(params, state, inputs, targets, forcings)\n",
        "  return loss, diagnostics, next_state, grads\n",
        "\n",
        "# Jax doesn't seem to like passing configs as args through the jit. Passing it\n",
        "# in via partial (instead of capture by closure) forces jax to invalidate the\n",
        "# jit cache if you change configs.\n",
        "def with_configs(fn):\n",
        "  return functools.partial(\n",
        "      fn, model_config=model_config, task_config=task_config)\n",
        "\n",
        "# Always pass params and state, so the usage below are simpler\n",
        "def with_params(fn):\n",
        "  return functools.partial(fn, params=params, state=state)\n",
        "\n",
        "# Our models aren't stateful, so the state is always empty, so just return the\n",
        "# predictions. This is requiredy by our rollout code, and generally simpler.\n",
        "def drop_state(fn):\n",
        "  return lambda **kw: fn(**kw)[0]\n",
        "\n",
        "init_jitted = jax.jit(with_configs(run_forward.init))\n",
        "\n",
        "if params is None:\n",
        "  params, state = init_jitted(\n",
        "      rng=jax.random.PRNGKey(0),\n",
        "      inputs=train_inputs,\n",
        "      targets_template=train_targets,\n",
        "      forcings=train_forcings)\n",
        "\n",
        "loss_fn_jitted = drop_state(with_params(jax.jit(with_configs(loss_fn.apply))))\n",
        "grads_fn_jitted = with_params(jax.jit(with_configs(grads_fn)))\n",
        "run_forward_jitted = drop_state(with_params(jax.jit(with_configs(\n",
        "    run_forward.apply))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VBNutliiCyqA"
      },
      "source": [
        "# 运行模型\n",
        "\n",
        "请注意，第一次运行下面的单元格可能需要一段时间（可能几分钟），因为这包括代码编译的时间。第二次运行时速度会明显加快。\n",
        "\n",
        "这将使用 python 循环迭代预测步骤，其中 1 步的预测是固定的。这比下面的训练步骤对内存的要求要低，应该可以使用小型 GraphCast 模型对 1 度分辨率数据进行 4 步预测。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7obeY9i9oTtD"
      },
      "outputs": [],
      "source": [
        "# @标题 递归计算（在 python 中的循环）\n",
        "\n",
        "assert model_config.resolution in (0, 360. / eval_inputs.sizes[\"lon\"]), (\n",
        "  \"Model resolution doesn't match the data resolution. You likely want to \"\n",
        "  \"re-filter the dataset list, and download the correct data.\")\n",
        "\n",
        "print(\"Inputs:  \", eval_inputs.dims.mapping)\n",
        "print(\"Targets: \", eval_targets.dims.mapping)\n",
        "print(\"Forcings:\", eval_forcings.dims.mapping)\n",
        "\n",
        "predictions = rollout.chunked_prediction(\n",
        "    run_forward_jitted,\n",
        "    rng=jax.random.PRNGKey(0),\n",
        "    inputs=eval_inputs,\n",
        "    targets_template=eval_targets * np.nan,\n",
        "    forcings=eval_forcings)\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "ft298eZskHtn"
      },
      "outputs": [],
      "source": [
        "# @title 选择要绘制的预测结果\n",
        "\n",
        "plot_pred_variable = widgets.Dropdown(\n",
        "    options=predictions.data_vars.keys(),\n",
        "    value=\"2m_temperature\",\n",
        "    description=\"变量\")\n",
        "plot_pred_level = widgets.Dropdown(\n",
        "    options=predictions.coords[\"level\"].values,\n",
        "    value=500,\n",
        "    description=\"级别\")\n",
        "plot_pred_robust = widgets.Checkbox(value=True, description=\"鲁棒性\")\n",
        "plot_pred_max_steps = widgets.IntSlider(\n",
        "    min=1,\n",
        "    max=predictions.dims[\"time\"],\n",
        "    value=predictions.dims[\"time\"],\n",
        "    description=\"最大步\")\n",
        "\n",
        "widgets.VBox([\n",
        "    plot_pred_variable,\n",
        "    plot_pred_level,\n",
        "    plot_pred_robust,\n",
        "    plot_pred_max_steps,\n",
        "    widgets.Label(value=\"运行下一个单元格，绘制预测结果。重新运行该单元格将清除您的选择。\")\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_tTdx6fmmj1I"
      },
      "outputs": [],
      "source": [
        "# @title 使用预测数据绘图\n",
        "\n",
        "\n",
        "plot_size = 5\n",
        "plot_max_steps = min(predictions.dims[\"time\"], plot_pred_max_steps.value)\n",
        "\n",
        "data = {\n",
        "    \"Targets\": scale(select(eval_targets, plot_pred_variable.value, plot_pred_level.value, plot_max_steps), robust=plot_pred_robust.value),\n",
        "    \"Predictions\": scale(select(predictions, plot_pred_variable.value, plot_pred_level.value, plot_max_steps), robust=plot_pred_robust.value),\n",
        "    \"Diff\": scale((select(eval_targets, plot_pred_variable.value, plot_pred_level.value, plot_max_steps) -\n",
        "                        select(predictions, plot_pred_variable.value, plot_pred_level.value, plot_max_steps)),\n",
        "                       robust=plot_pred_robust.value, center=0),\n",
        "}\n",
        "fig_title = plot_pred_variable.value\n",
        "if \"level\" in predictions[plot_pred_variable.value].coords:\n",
        "  fig_title += f\" at {plot_pred_level.value} hPa\"\n",
        "\n",
        "plot_data(data, fig_title, plot_size, plot_pred_robust.value)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pa78b64bLYe1"
      },
      "source": [
        "# 训练模型\n",
        "\n",
        "以下操作需要大量内存，而且根据所使用的加速器，只能在低分辨率数据上拟合很小的 \"随机 \"模型。它使用上面选择的训练步数。\n",
        "\n",
        "第一次执行单元需要更多时间，因为其中包括函数的 jit 时间。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "Nv-u3dAP7IRZ"
      },
      "outputs": [],
      "source": [
        "# @title 损失计算（多步骤递归（自回归）损失）\n",
        "loss, diagnostics = loss_fn_jitted(\n",
        "    rng=jax.random.PRNGKey(0),\n",
        "    inputs=train_inputs,\n",
        "    targets=train_targets,\n",
        "    forcings=train_forcings)\n",
        "\n",
        "print(\"Loss:\", float(loss))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "mBNFq1IGZNLz"
      },
      "outputs": [],
      "source": [
        "# @title 梯度计算（通过时间进行反推）\n",
        "loss, diagnostics, next_state, grads = grads_fn_jitted(\n",
        "    inputs=train_inputs,\n",
        "    targets=train_targets,\n",
        "    forcings=train_forcings)\n",
        "mean_grad = np.mean(jax.tree_util.tree_flatten(jax.tree_util.tree_map(lambda x: np.abs(x).mean(), grads))[0])\n",
        "print(f\"Loss: {loss:.4f}, Mean |grad|: {mean_grad:.6f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "J4FJFKWD8Loz"
      },
      "outputs": [],
      "source": [
        "# @title 递归（自回归）推出（在 JAX 中保持循环）\n",
        "print(\"Inputs:  \", train_inputs.dims.mapping)\n",
        "print(\"Targets: \", train_targets.dims.mapping)\n",
        "print(\"Forcings:\", train_forcings.dims.mapping)\n",
        "\n",
        "predictions = run_forward_jitted(\n",
        "    rng=jax.random.PRNGKey(0),\n",
        "    inputs=train_inputs,\n",
        "    targets_template=train_targets * np.nan,\n",
        "    forcings=train_forcings)\n",
        "predictions"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "GraphCast",
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
